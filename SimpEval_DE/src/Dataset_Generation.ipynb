{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:29:03.466301Z",
     "iopub.status.busy": "2025-03-15T21:29:03.466028Z",
     "iopub.status.idle": "2025-03-15T21:29:03.468951Z",
     "shell.execute_reply": "2025-03-15T21:29:03.468493Z",
     "shell.execute_reply.started": "2025-03-15T21:29:03.466279Z"
    }
   },
   "source": [
    "# SimpEvalDE Generation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines the procedure for recreating the SimpEvalDE dataset, which was used to train and validate the [DETECT](add your citation here) metric for German text simplification evaluation.\n",
    "\n",
    "Compiling this dataset requires obtaining access permissions for two proprietary datasets that form the foundation of SimpEvalDE:\n",
    "\n",
    "1. APA-LHA — (Spring et al., 2021)\n",
    "https://zenodo.org/records/5148163\n",
    "\n",
    "2. DEplain — (Stodden et al., 2023)\n",
    "https://zenodo.org/records/7674560\n",
    "\n",
    "Once you have permission to use these datasets, you should also download the additional data files required for assembling SimpEvalDE from the Hugging Face repository: ➡️ https://huggingface.co/datasets/ZurichNLP/SimpEvalDE\n",
    "\n",
    "After obtaining all required files, specify the dataset paths in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Hugging Face data components (e.g., generations, scores, human grades)\n",
    "data_path = \"../data\"\n",
    "\n",
    "# Paths to the proprietary datasets (must be obtained separately)\n",
    "apa_lha_path = \"../data/apa_lha\"\n",
    "deplain_path = \"../data/deplain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the notebook to merge, filter, and augment the datasets as described on HuggingFace. The script outputs `SimpEvalDE_train.csv` and `SimpEvalDE_test.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:49:24.055183Z",
     "iopub.status.busy": "2025-03-31T15:49:24.055048Z",
     "iopub.status.idle": "2025-03-31T15:49:24.099006Z",
     "shell.execute_reply": "2025-03-31T15:49:24.098672Z",
     "shell.execute_reply.started": "2025-03-31T15:49:24.055166Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:49:24.100103Z",
     "iopub.status.busy": "2025-03-31T15:49:24.099780Z",
     "iopub.status.idle": "2025-03-31T15:49:34.708550Z",
     "shell.execute_reply": "2025-03-31T15:49:34.707940Z",
     "shell.execute_reply.started": "2025-03-31T15:49:24.100085Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:49:34.709676Z",
     "iopub.status.busy": "2025-03-31T15:49:34.709432Z",
     "iopub.status.idle": "2025-03-31T15:50:20.021740Z",
     "shell.execute_reply": "2025-03-31T15:50:20.021115Z",
     "shell.execute_reply.started": "2025-03-31T15:49:34.709658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\envs\\ATS_LENS_DE\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\maria\\anaconda3\\envs\\ATS_LENS_DE\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:10.432856Z",
     "iopub.status.busy": "2025-03-30T21:45:10.432593Z",
     "iopub.status.idle": "2025-03-30T21:45:10.436246Z",
     "shell.execute_reply": "2025-03-30T21:45:10.435843Z",
     "shell.execute_reply.started": "2025-03-30T21:45:10.432839Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Cleans a sentence to ensure it ends with a single full stop.\n",
    "    - Adds a full stop if missing.\n",
    "    - Fixes cases where it ends with ' .'.\n",
    "    \n",
    "    :param sentence: The sentence to clean.\n",
    "    :return: Cleaned sentence with a proper full stop.\n",
    "    \"\"\"\n",
    "    sentence = sentence.strip()  # Remove leading/trailing spaces\n",
    "    \n",
    "    # Fix cases where sentence ends with \" .\"\n",
    "    if sentence.endswith(\" .\"):\n",
    "        sentence = sentence[:-2]  # Remove the extra space and dot\n",
    "    \n",
    "    # Ensure the sentence ends with a single full stop\n",
    "    if not sentence.endswith(\".\"):\n",
    "        sentence += \".\"\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:10.437650Z",
     "iopub.status.busy": "2025-03-30T21:45:10.437443Z",
     "iopub.status.idle": "2025-03-30T21:45:10.562029Z",
     "shell.execute_reply": "2025-03-30T21:45:10.561576Z",
     "shell.execute_reply.started": "2025-03-30T21:45:10.437635Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_and_combine(original, simplified):\n",
    "    \"\"\"\n",
    "    Maps original sentences to their corresponding simplified sentences, ensuring proper cleaning.\n",
    "    Flags sentences where any of their simplifications are also mapped to by other original sentences.\n",
    "    Exports the results to a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    mapping = defaultdict(list)\n",
    "    reverse_mapping = defaultdict(set)\n",
    "\n",
    "    # Step 1: Clean sentences\n",
    "    original = [clean_sentence(o) for o in original]\n",
    "    simplified = [clean_sentence(s) for s in simplified]\n",
    "\n",
    "    # Step 2: Build mapping (Original → Simplified)\n",
    "    for orig, simp in zip(original, simplified):\n",
    "        mapping[orig].append(simp)\n",
    "        reverse_mapping[simp].add(orig)  # Track which originals a simplified sentence belongs to\n",
    "\n",
    "    # Step 3: Identify problematic mappings\n",
    "    problematic_simplifications = {simp for simp, origs in reverse_mapping.items() if len(origs) > 1}\n",
    "\n",
    "    # Step 4: Generate Data for DataFrame\n",
    "    data = []\n",
    "    for orig, simps in mapping.items():\n",
    "        joined_simps = \" \".join(simps)  # Join simplified sentences\n",
    "        num_simplified = len(simps)  # Count number of simplifications\n",
    "        is_problematic = any(simp in problematic_simplifications for simp in simps)  # Flag if any simplified sentence is problematic\n",
    "        data.append({\n",
    "            \"original\": orig,\n",
    "            \"simplified\": joined_simps,\n",
    "            \"no_sentences\": num_simplified,\n",
    "            \"multi\": is_problematic  # True if any of the simplifications are shared across multiple originals\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:10.563188Z",
     "iopub.status.busy": "2025-03-30T21:45:10.562885Z",
     "iopub.status.idle": "2025-03-30T21:45:10.570558Z",
     "shell.execute_reply": "2025-03-30T21:45:10.570129Z",
     "shell.execute_reply.started": "2025-03-30T21:45:10.563170Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_multiple_orig_matches(df, original, simplification):\n",
    "    return df[df.groupby([simplification])[original].transform('count') == 1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.250322Z",
     "iopub.status.busy": "2025-03-15T21:33:46.249359Z",
     "iopub.status.idle": "2025-03-15T21:33:46.253875Z",
     "shell.execute_reply": "2025-03-15T21:33:46.253428Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.250301Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_extra_space(df, columns):\n",
    "    for column in columns:\n",
    "        print(column)\n",
    "        df[column] = df[column].str.replace(r'\\s+([.,])', r'\\1', regex=True)\n",
    "        df[column] = df[column].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:33.463781Z",
     "iopub.status.busy": "2025-03-15T21:35:33.463507Z",
     "iopub.status.idle": "2025-03-15T21:35:33.466734Z",
     "shell.execute_reply": "2025-03-15T21:35:33.466330Z",
     "shell.execute_reply.started": "2025-03-15T21:35:33.463761Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_score_with_length(bert_scores, word_counts):\n",
    "\n",
    "    max_word_count = max(word_counts)  # Find the longest sentence in the dataset\n",
    "    adjusted_scores = [\n",
    "        bs * (np.log(max_word_count + 1) / np.log(wc + 1)) if wc > 0 else 0\n",
    "        for bs, wc in zip(bert_scores, word_counts)\n",
    "    ]\n",
    "    return adjusted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:33.467586Z",
     "iopub.status.busy": "2025-03-15T21:35:33.467317Z",
     "iopub.status.idle": "2025-03-15T21:35:33.479811Z",
     "shell.execute_reply": "2025-03-15T21:35:33.479422Z",
     "shell.execute_reply.started": "2025-03-15T21:35:33.467567Z"
    }
   },
   "outputs": [],
   "source": [
    "def bert_score(df, orig, simp):\n",
    "    P, R, F1 = score(df[orig].tolist(), df[simp].tolist(), lang=\"de\", rescale_with_baseline=True)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FK_score(text):\n",
    "    flesch_kincaid = textstat.flesch_reading_ease(text)\n",
    "    return flesch_kincaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_metrics(text):\n",
    "    # Tokenize using spaCy\n",
    "    doc = nlp(text)\n",
    "    num_words = len([token.text for token in doc if token.is_alpha])\n",
    "    sentence_count = len(list(doc.sents))\n",
    "    avg_word_length = sum(len(token.text) for token in doc) / num_words if num_words > 0 else 0\n",
    "    #flesch_kincaid = textstat.flesch_reading_ease(text)\n",
    "    return num_words, avg_word_length, sentence_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_text_metrics(df, orig_col, simp_col):\n",
    "    \"\"\"\n",
    "    Compute three text metrics:\n",
    "    1. Word Reduction Ratio (original words / simplified words)\n",
    "    2. Sentence Reduction Ratio (original sentences / simplified sentences)\n",
    "    3. ROUGE-1 Score between original and simplified text.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'original' and simplification columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with additional metric columns.\n",
    "    \"\"\"\n",
    "\n",
    "    #orig_word_counts = []\n",
    "    word_ratios = []\n",
    "    sentence_ratios = []\n",
    "    word_counts = []\n",
    "    #bert_scores = []\n",
    "    #FK_scores = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        original = row[orig_col]\n",
    "        simplification = row[simp_col]\n",
    "        #reference = row[ref_col]\n",
    "\n",
    "        # Tokenize using spaCy\n",
    "        orig_doc = nlp(original)\n",
    "        simp_doc = nlp(simplification)\n",
    "\n",
    "        # Word count\n",
    "        orig_word_count = len([token.text for token in orig_doc if token.is_alpha])\n",
    "        simp_word_count = len([token.text for token in simp_doc if token.is_alpha])\n",
    "        word_ratio = orig_word_count / simp_word_count if simp_word_count > 0 else 0\n",
    "\n",
    "        # Sentence count\n",
    "        orig_sentence_count = len(list(orig_doc.sents))\n",
    "        simp_sentence_count = len(list(simp_doc.sents))\n",
    "        sentence_ratio = orig_sentence_count / simp_sentence_count if simp_sentence_count > 0 else 0\n",
    "\n",
    " \n",
    "\n",
    "        word_counts.append(orig_word_count)\n",
    "        word_ratios.append(word_ratio)\n",
    "        sentence_ratios.append(sentence_ratio)\n",
    "        #FK_scores.append(complexity_score)\n",
    "\n",
    "    # Add metrics to DataFrame\n",
    "    df[\"WordReductionRatio\"] = word_ratios\n",
    "    df[\"WordCountOrig\"] = word_counts\n",
    "    df[\"SentenceReductionRatio\"] = sentence_ratios\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_simplifications(df):\n",
    "    df = df.copy()  # Avoid modifying the original dataframe\n",
    "    df[\"simplifications\"] = df.apply(\n",
    "        lambda row: [val for val in [row[\"simplified_B1\"], row[\"simplified_A2\"]] if pd.notna(val)],\n",
    "        axis=1\n",
    "    )\n",
    "    return df[[\"original\", \"simplifications\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Skip cleaning if it's not a string (e.g., NaN)\n",
    "\n",
    "    # Keep only the first line\n",
    "    first_line = text.strip().split('\\n')[0]\n",
    "\n",
    "    # Remove specific prefixes if present\n",
    "    for prefix in [\"Ausgabe:\", \"Eingabe:\"]:\n",
    "        if first_line.startswith(prefix):\n",
    "            first_line = first_line[len(prefix):].strip()\n",
    "\n",
    "    return first_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APA-LHA Original-B1-A2 Dataset Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:29:42.944894Z",
     "iopub.status.busy": "2025-03-15T21:29:42.944423Z",
     "iopub.status.idle": "2025-03-15T21:29:42.972519Z",
     "shell.execute_reply": "2025-03-15T21:29:42.972114Z",
     "shell.execute_reply.started": "2025-03-15T21:29:42.944875Z"
    }
   },
   "outputs": [],
   "source": [
    "A2_OR_mapped_out = pd.DataFrame(columns=['fileID', 'original', 'simplified', 'no_sentences', 'multi'])\n",
    "A2_OR_mapping_dir = f\"{apa_lha_path}A2-OR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:29:42.974773Z",
     "iopub.status.busy": "2025-03-15T21:29:42.974486Z",
     "iopub.status.idle": "2025-03-15T21:31:55.152498Z",
     "shell.execute_reply": "2025-03-15T21:31:55.151951Z",
     "shell.execute_reply.started": "2025-03-15T21:29:42.974754Z"
    }
   },
   "outputs": [],
   "source": [
    "files_dir = os.listdir(A2_OR_mapping_dir)\n",
    "files_mapped = list(set([\"_\".join(file_dir.split('_')[0:2]) for file_dir in files_dir if file_dir.endswith(\".simpde\")]))\n",
    "\n",
    "for file_mapped in files_mapped:\n",
    "    orig_path = os.path.join(A2_OR_mapping_dir, f\"{file_mapped}.de\")\n",
    "    simp_path = os.path.join(A2_OR_mapping_dir, f\"{file_mapped}_A2.simpde\")\n",
    "\n",
    "    with open(orig_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        orig_sentences = [line.strip() for line in file]  \n",
    "    with open(simp_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        simp_sentences = [line.strip() for line in file]  \n",
    "\n",
    "    #combined_mapping = map_and_combine(orig_sentences, simp_sentences)\n",
    "    # new_rows = pd.DataFrame([\n",
    "    #     {\"fileID\": file_mapped, \"original\": orig, \"simplified\": simp} \n",
    "    #     for orig, simp in combined_mapping.items()\n",
    "    # ])\n",
    "    new_rows = map_and_combine(orig_sentences, simp_sentences)\n",
    "    new_rows['fileID'] = file_mapped\n",
    "    A2_OR_mapped_out = pd.concat([A2_OR_mapped_out, new_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:31:55.153752Z",
     "iopub.status.busy": "2025-03-15T21:31:55.153287Z",
     "iopub.status.idle": "2025-03-15T21:31:55.164946Z",
     "shell.execute_reply": "2025-03-15T21:31:55.164514Z",
     "shell.execute_reply.started": "2025-03-15T21:31:55.153730Z"
    }
   },
   "outputs": [],
   "source": [
    "A2_OR_mapped_out_dedup = remove_multiple_orig_matches(A2_OR_mapped_out, 'original', 'simplified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:31:55.166466Z",
     "iopub.status.busy": "2025-03-15T21:31:55.165667Z",
     "iopub.status.idle": "2025-03-15T21:31:55.278753Z",
     "shell.execute_reply": "2025-03-15T21:31:55.278350Z",
     "shell.execute_reply.started": "2025-03-15T21:31:55.166444Z"
    }
   },
   "outputs": [],
   "source": [
    "B1_OR_mapped_out = pd.DataFrame(columns=['fileID', 'original', 'simplified', 'no_sentences', 'multi'])\n",
    "B1_OR_mapping_dir = f\"{apa_lha_path}B1-OR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:31:55.280156Z",
     "iopub.status.busy": "2025-03-15T21:31:55.279379Z",
     "iopub.status.idle": "2025-03-15T21:33:45.600606Z",
     "shell.execute_reply": "2025-03-15T21:33:45.600066Z",
     "shell.execute_reply.started": "2025-03-15T21:31:55.280136Z"
    }
   },
   "outputs": [],
   "source": [
    "files_dir = os.listdir(B1_OR_mapping_dir)\n",
    "files_mapped = list(set([\"_\".join(file_dir.split('_')[0:2]) for file_dir in files_dir if file_dir.endswith(\".simpde\")]))\n",
    "\n",
    "for file_mapped in files_mapped:\n",
    "    orig_path = os.path.join(B1_OR_mapping_dir, f\"{file_mapped}.de\")\n",
    "    simp_path = os.path.join(B1_OR_mapping_dir, f\"{file_mapped}_B1.simpde\")\n",
    "\n",
    "    with open(orig_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        orig_sentences = [line.strip() for line in file]  \n",
    "    with open(simp_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        simp_sentences = [line.strip() for line in file]  \n",
    "\n",
    "    #combined_mapping = map_and_combine(orig_sentences, simp_sentences)\n",
    "    # new_rows = pd.DataFrame([\n",
    "    #     {\"fileID\": file_mapped, \"original\": orig, \"simplified\": simp} \n",
    "    #     for orig, simp in combined_mapping.items()\n",
    "    # ])\n",
    "    new_rows = map_and_combine(orig_sentences, simp_sentences)\n",
    "    new_rows['fileID'] = file_mapped\n",
    "    B1_OR_mapped_out = pd.concat([B1_OR_mapped_out, new_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:45.602142Z",
     "iopub.status.busy": "2025-03-15T21:33:45.601437Z",
     "iopub.status.idle": "2025-03-15T21:33:45.614200Z",
     "shell.execute_reply": "2025-03-15T21:33:45.613774Z",
     "shell.execute_reply.started": "2025-03-15T21:33:45.602122Z"
    }
   },
   "outputs": [],
   "source": [
    "B1_OR_mapped_out_dedup = remove_multiple_orig_matches(B1_OR_mapped_out, 'original', 'simplified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:45.615467Z",
     "iopub.status.busy": "2025-03-15T21:33:45.614904Z",
     "iopub.status.idle": "2025-03-15T21:33:45.661302Z",
     "shell.execute_reply": "2025-03-15T21:33:45.660771Z",
     "shell.execute_reply.started": "2025-03-15T21:33:45.615445Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(B1_OR_mapped_out_dedup, A2_OR_mapped_out_dedup, on=[\"fileID\", \"original\"], suffixes=(\"_B1\", \"_A2\"), how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge APA-LHA with DePLAIN-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For SimpEvalDE, only the test subset of DePLAIN is used as two of the LLMs used for further ATS generation are trained on the train+dev subsets of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T07:28:58.772385Z",
     "iopub.status.busy": "2025-03-26T07:28:58.771990Z",
     "iopub.status.idle": "2025-03-26T07:28:58.820551Z",
     "shell.execute_reply": "2025-03-26T07:28:58.819614Z",
     "shell.execute_reply.started": "2025-03-26T07:28:58.772354Z"
    }
   },
   "outputs": [],
   "source": [
    "test_deplain = pd.read_csv(f\"{deplain_path}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.256375Z",
     "iopub.status.busy": "2025-03-15T21:33:46.255420Z",
     "iopub.status.idle": "2025-03-15T21:33:46.361926Z",
     "shell.execute_reply": "2025-03-15T21:33:46.361273Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.256356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "simplified_B1\n",
      "simplified_A2\n"
     ]
    }
   ],
   "source": [
    "#clean datasets\n",
    "merged_df = remove_extra_space(merged_df, ['original', 'simplified_B1', 'simplified_A2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.384571Z",
     "iopub.status.busy": "2025-03-15T21:33:46.384413Z",
     "iopub.status.idle": "2025-03-15T21:33:46.535491Z",
     "shell.execute_reply": "2025-03-15T21:33:46.534888Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.384555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "simplified\n"
     ]
    }
   ],
   "source": [
    "A2_OR_mapped_out_dedup = remove_extra_space(A2_OR_mapped_out_dedup, ['original', 'simplified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.540244Z",
     "iopub.status.busy": "2025-03-15T21:33:46.540066Z",
     "iopub.status.idle": "2025-03-15T21:33:46.661634Z",
     "shell.execute_reply": "2025-03-15T21:33:46.660993Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.540227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "simplified\n"
     ]
    }
   ],
   "source": [
    "B1_OR_mapped_out_dedup = remove_extra_space(B1_OR_mapped_out_dedup, ['original', 'simplified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 1 - A2 and B1 joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.662671Z",
     "iopub.status.busy": "2025-03-15T21:33:46.662482Z",
     "iopub.status.idle": "2025-03-15T21:33:46.669642Z",
     "shell.execute_reply": "2025-03-15T21:33:46.669010Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.662651Z"
    }
   },
   "outputs": [],
   "source": [
    "#first join deplain where both B1 and A2 simplifications align - hopefully makes the original mapping the best\n",
    "slice_deplain_test_merged = pd.merge(merged_df, test_deplain[['original', 'simplification', 'alignment']], left_on=['simplified_B1', 'simplified_A2'], right_on=['original', 'simplification'], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.694052Z",
     "iopub.status.busy": "2025-03-15T21:33:46.693889Z",
     "iopub.status.idle": "2025-03-15T21:33:46.706371Z",
     "shell.execute_reply": "2025-03-15T21:33:46.705624Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.694035Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_merged = slice_deplain_test_merged.drop(columns = ['no_sentences_B1', 'multi_B1', 'no_sentences', 'multi_A2', 'no_sentences_A2', 'original_y', 'simplification'])\n",
    "slice_deplain_test_merged.columns = ['fileID', 'original', 'simplified_B1', 'simplified_A2', 'alignment']\n",
    "slice_deplain_test_merged['align'] = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.707139Z",
     "iopub.status.busy": "2025-03-15T21:33:46.706984Z",
     "iopub.status.idle": "2025-03-15T21:33:46.738261Z",
     "shell.execute_reply": "2025-03-15T21:33:46.737537Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.707123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_deplain_test_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 2 - Join by B1 only and merge A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.739185Z",
     "iopub.status.busy": "2025-03-15T21:33:46.739021Z",
     "iopub.status.idle": "2025-03-15T21:33:46.760756Z",
     "shell.execute_reply": "2025-03-15T21:33:46.760114Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.739168Z"
    }
   },
   "outputs": [],
   "source": [
    "#first remove the simplifications that were already done\n",
    "# Then match by B1_Ze = B1_De and join Deplain B1_De -> A2_De simplification, Orig-B1 should be checked\n",
    "# # this also keeps the items that were removed via remove_multiple_orig_matches, but that is okay because they will get filtered out again\n",
    "# Have to match by the original to avoid getting mapped incorrect mappings that don't correspond in Deplain, where \n",
    "slice_deplain_test_B1 = B1_OR_mapped_out_dedup[~B1_OR_mapped_out_dedup['original'].isin(slice_deplain_test_merged['original'])]\n",
    "slice_deplain_test_B1 = pd.merge(slice_deplain_test_B1,  test_deplain[['original', 'simplification', 'alignment']], left_on='simplified', right_on='original', how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.761627Z",
     "iopub.status.busy": "2025-03-15T21:33:46.761435Z",
     "iopub.status.idle": "2025-03-15T21:33:46.772956Z",
     "shell.execute_reply": "2025-03-15T21:33:46.772355Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.761609Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_B1 = remove_multiple_orig_matches(slice_deplain_test_B1, 'original_x', 'original_y') #120 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.797041Z",
     "iopub.status.busy": "2025-03-15T21:33:46.796829Z",
     "iopub.status.idle": "2025-03-15T21:33:46.801572Z",
     "shell.execute_reply": "2025-03-15T21:33:46.800860Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.797022Z"
    }
   },
   "outputs": [],
   "source": [
    "#renaming and cleaning\n",
    "slice_deplain_test_B1 = slice_deplain_test_B1.drop(columns = ['original_y', 'multi', 'no_sentences'])\n",
    "slice_deplain_test_B1.columns = ['fileID', 'original', 'simplified_B1', 'simplified_A2', 'alignment']\n",
    "slice_deplain_test_B1['align'] = \"Deplain_B1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 3 - join By A2 only and merge B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.825309Z",
     "iopub.status.busy": "2025-03-15T21:33:46.825155Z",
     "iopub.status.idle": "2025-03-15T21:33:46.839040Z",
     "shell.execute_reply": "2025-03-15T21:33:46.838443Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.825293Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_A2 = A2_OR_mapped_out_dedup[~A2_OR_mapped_out_dedup['original'].isin((slice_deplain_test_merged['original']).tolist() +slice_deplain_test_B1['original'].tolist())]\n",
    "slice_deplain_test_A2 = pd.merge(slice_deplain_test_A2,  test_deplain[['original', 'simplification', 'alignment']], left_on='simplified', right_on='simplification', how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.910770Z",
     "iopub.status.busy": "2025-03-15T21:33:46.910599Z",
     "iopub.status.idle": "2025-03-15T21:33:46.927754Z",
     "shell.execute_reply": "2025-03-15T21:33:46.927168Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.910753Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_A2 = remove_multiple_orig_matches(slice_deplain_test_A2, 'original_x', 'original_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.928660Z",
     "iopub.status.busy": "2025-03-15T21:33:46.928492Z",
     "iopub.status.idle": "2025-03-15T21:33:46.958914Z",
     "shell.execute_reply": "2025-03-15T21:33:46.958394Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.928642Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_A2 = slice_deplain_test_A2.drop(columns = ['simplified', 'no_sentences', 'no_sentences', 'multi'])\n",
    "slice_deplain_test_A2.columns = ['fileID', 'original', 'simplified_B1', 'simplified_A2', 'alignment']\n",
    "slice_deplain_test_A2['align'] = \"Deplain_A2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:46.959838Z",
     "iopub.status.busy": "2025-03-15T21:33:46.959682Z",
     "iopub.status.idle": "2025-03-15T21:33:47.004372Z",
     "shell.execute_reply": "2025-03-15T21:33:47.003714Z",
     "shell.execute_reply.started": "2025-03-15T21:33:46.959822Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_deplain_test_A2  #95 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate all 3 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.005409Z",
     "iopub.status.busy": "2025-03-15T21:33:47.005250Z",
     "iopub.status.idle": "2025-03-15T21:33:47.044994Z",
     "shell.execute_reply": "2025-03-15T21:33:47.044472Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.005392Z"
    }
   },
   "outputs": [],
   "source": [
    "full_deplain_set = pd.concat([slice_deplain_test_merged, slice_deplain_test_B1, slice_deplain_test_A2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.045963Z",
     "iopub.status.busy": "2025-03-15T21:33:47.045794Z",
     "iopub.status.idle": "2025-03-15T21:33:47.064492Z",
     "shell.execute_reply": "2025-03-15T21:33:47.063967Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.045945Z"
    }
   },
   "outputs": [],
   "source": [
    "full_deplain_set = remove_multiple_orig_matches(full_deplain_set, 'original', 'simplified_B1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.065437Z",
     "iopub.status.busy": "2025-03-15T21:33:47.065278Z",
     "iopub.status.idle": "2025-03-15T21:33:47.085859Z",
     "shell.execute_reply": "2025-03-15T21:33:47.085168Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.065419Z"
    }
   },
   "outputs": [],
   "source": [
    "full_deplain_set = remove_multiple_orig_matches(full_deplain_set, 'original', 'simplified_A2') #216 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.087045Z",
     "iopub.status.busy": "2025-03-15T21:33:47.086837Z",
     "iopub.status.idle": "2025-03-15T21:33:47.099101Z",
     "shell.execute_reply": "2025-03-15T21:33:47.098554Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.087028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_deplain_set['simplified_A2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.100181Z",
     "iopub.status.busy": "2025-03-15T21:33:47.100020Z",
     "iopub.status.idle": "2025-03-15T21:33:47.114170Z",
     "shell.execute_reply": "2025-03-15T21:33:47.113596Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.100166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_deplain_set['simplified_B1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:33:47.115152Z",
     "iopub.status.busy": "2025-03-15T21:33:47.114993Z",
     "iopub.status.idle": "2025-03-15T21:33:47.135003Z",
     "shell.execute_reply": "2025-03-15T21:33:47.134543Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.115136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_deplain_set['original'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add unmatched rows to map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out texts in merged dataset or DEPlaintrain+dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:49.609938Z",
     "iopub.status.busy": "2025-03-15T21:34:49.609441Z",
     "iopub.status.idle": "2025-03-15T21:34:49.796273Z",
     "shell.execute_reply": "2025-03-15T21:34:49.795754Z",
     "shell.execute_reply.started": "2025-03-15T21:34:49.609914Z"
    }
   },
   "outputs": [],
   "source": [
    "train_deplain = pd.read_csv(f\"{deplain_path}/train.csv\")\n",
    "dev_deplain = pd.read_csv(f\"{deplain_path}/dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:50.058903Z",
     "iopub.status.busy": "2025-03-15T21:34:50.058548Z",
     "iopub.status.idle": "2025-03-15T21:34:50.062691Z",
     "shell.execute_reply": "2025-03-15T21:34:50.062250Z",
     "shell.execute_reply.started": "2025-03-15T21:34:50.058883Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dev_deplain = pd.concat([train_deplain, dev_deplain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:50.429935Z",
     "iopub.status.busy": "2025-03-15T21:34:50.429585Z",
     "iopub.status.idle": "2025-03-15T21:34:50.436989Z",
     "shell.execute_reply": "2025-03-15T21:34:50.436543Z",
     "shell.execute_reply.started": "2025-03-15T21:34:50.429913Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df_nontrain = merged_df[(~merged_df['simplified_B1'].isin(train_dev_deplain['original'])) & (~merged_df['simplified_A2'].isin(train_dev_deplain['simplification']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:50.819255Z",
     "iopub.status.busy": "2025-03-15T21:34:50.818769Z",
     "iopub.status.idle": "2025-03-15T21:34:50.822793Z",
     "shell.execute_reply": "2025-03-15T21:34:50.822384Z",
     "shell.execute_reply.started": "2025-03-15T21:34:50.819232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_nontrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:51.684346Z",
     "iopub.status.busy": "2025-03-15T21:34:51.684044Z",
     "iopub.status.idle": "2025-03-15T21:34:51.687963Z",
     "shell.execute_reply": "2025-03-15T21:34:51.687580Z",
     "shell.execute_reply.started": "2025-03-15T21:34:51.684327Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df_nontrain_unmatched = merged_df_nontrain[~merged_df_nontrain['original'].isin(full_deplain_set['original'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:53.614022Z",
     "iopub.status.busy": "2025-03-15T21:34:53.613583Z",
     "iopub.status.idle": "2025-03-15T21:34:53.617325Z",
     "shell.execute_reply": "2025-03-15T21:34:53.616937Z",
     "shell.execute_reply.started": "2025-03-15T21:34:53.613999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_nontrain_unmatched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:54.000107Z",
     "iopub.status.busy": "2025-03-15T21:34:53.999788Z",
     "iopub.status.idle": "2025-03-15T21:34:54.004367Z",
     "shell.execute_reply": "2025-03-15T21:34:54.003986Z",
     "shell.execute_reply.started": "2025-03-15T21:34:54.000089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sctmp/mkorob/ipykernel_969762/698138204.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df_nontrain_unmatched['alignment'] = merged_df_nontrain_unmatched['no_sentences_B1'].astype(str) + \":\" + merged_df_nontrain_unmatched['no_sentences_A2'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "merged_df_nontrain_unmatched['alignment'] = merged_df_nontrain_unmatched['no_sentences_B1'].astype(str) + \":\" + merged_df_nontrain_unmatched['no_sentences_A2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:54.363931Z",
     "iopub.status.busy": "2025-03-15T21:34:54.363631Z",
     "iopub.status.idle": "2025-03-15T21:34:54.366921Z",
     "shell.execute_reply": "2025-03-15T21:34:54.366528Z",
     "shell.execute_reply.started": "2025-03-15T21:34:54.363913Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df_nontrain_unmatched = merged_df_nontrain_unmatched.drop(columns = [\"multi_B1\", \"no_sentences_B1\", \"multi_A2\", \"no_sentences_A2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:55.279428Z",
     "iopub.status.busy": "2025-03-15T21:34:55.279144Z",
     "iopub.status.idle": "2025-03-15T21:34:55.281902Z",
     "shell.execute_reply": "2025-03-15T21:34:55.281434Z",
     "shell.execute_reply.started": "2025-03-15T21:34:55.279408Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df_nontrain_unmatched['align'] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:34:56.831565Z",
     "iopub.status.busy": "2025-03-15T21:34:56.831135Z",
     "iopub.status.idle": "2025-03-15T21:34:56.835170Z",
     "shell.execute_reply": "2025-03-15T21:34:56.834737Z",
     "shell.execute_reply.started": "2025-03-15T21:34:56.831541Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df = pd.concat([merged_df_nontrain_unmatched, full_deplain_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:01.011310Z",
     "iopub.status.busy": "2025-03-15T21:35:01.010865Z",
     "iopub.status.idle": "2025-03-15T21:35:01.018392Z",
     "shell.execute_reply": "2025-03-15T21:35:01.017937Z",
     "shell.execute_reply.started": "2025-03-15T21:35:01.011287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileID</th>\n",
       "      <th>original</th>\n",
       "      <th>simplified_B1</th>\n",
       "      <th>simplified_A2</th>\n",
       "      <th>alignment</th>\n",
       "      <th>align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fileID, original, simplified_B1, simplified_A2, alignment, align]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Both of these simplifications do not correspond to the original\n",
    "full_merged_df[full_merged_df['simplified_A2'].duplicated(keep=False)].sort_values(by = \"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:01.718844Z",
     "iopub.status.busy": "2025-03-15T21:35:01.718525Z",
     "iopub.status.idle": "2025-03-15T21:35:01.725304Z",
     "shell.execute_reply": "2025-03-15T21:35:01.724900Z",
     "shell.execute_reply.started": "2025-03-15T21:35:01.718823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileID</th>\n",
       "      <th>original</th>\n",
       "      <th>simplified_B1</th>\n",
       "      <th>simplified_A2</th>\n",
       "      <th>alignment</th>\n",
       "      <th>align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fileID, original, simplified_B1, simplified_A2, alignment, align]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df[full_merged_df['simplified_B1'].duplicated(keep=False)].sort_values(by = \"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:02.217593Z",
     "iopub.status.busy": "2025-03-15T21:35:02.217242Z",
     "iopub.status.idle": "2025-03-15T21:35:02.223436Z",
     "shell.execute_reply": "2025-03-15T21:35:02.223019Z",
     "shell.execute_reply.started": "2025-03-15T21:35:02.217572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileID</th>\n",
       "      <th>original</th>\n",
       "      <th>simplified_B1</th>\n",
       "      <th>simplified_A2</th>\n",
       "      <th>alignment</th>\n",
       "      <th>align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fileID, original, simplified_B1, simplified_A2, alignment, align]\n",
       "Index: []"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df[full_merged_df['original'].duplicated(keep=False)].sort_values(by = \"original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Metrics to select highly likely candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:11.502102Z",
     "iopub.status.busy": "2025-03-15T21:35:11.501837Z",
     "iopub.status.idle": "2025-03-15T21:35:18.992305Z",
     "shell.execute_reply": "2025-03-15T21:35:18.991750Z",
     "shell.execute_reply.started": "2025-03-15T21:35:11.502083Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df[['num_words_orig', 'avg_word_length_orig']] = full_merged_df['original'].apply(\n",
    "    lambda x: pd.Series(get_text_metrics(str(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:18.994003Z",
     "iopub.status.busy": "2025-03-15T21:35:18.993728Z",
     "iopub.status.idle": "2025-03-15T21:35:26.582902Z",
     "shell.execute_reply": "2025-03-15T21:35:26.582326Z",
     "shell.execute_reply.started": "2025-03-15T21:35:18.993983Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df[['num_words_B1', 'avg_word_length_B1']] = full_merged_df['simplified_B1'].apply(\n",
    "    lambda x: pd.Series(get_text_metrics(str(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:26.584033Z",
     "iopub.status.busy": "2025-03-15T21:35:26.583743Z",
     "iopub.status.idle": "2025-03-15T21:35:33.462646Z",
     "shell.execute_reply": "2025-03-15T21:35:33.462073Z",
     "shell.execute_reply.started": "2025-03-15T21:35:26.584012Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df[['num_words_A2', 'avg_word_length_A2']] = full_merged_df['simplified_A2'].apply(\n",
    "    lambda x: pd.Series(get_text_metrics(str(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:35:33.480725Z",
     "iopub.status.busy": "2025-03-15T21:35:33.480398Z",
     "iopub.status.idle": "2025-03-15T21:37:50.891154Z",
     "shell.execute_reply": "2025-03-15T21:37:50.890217Z",
     "shell.execute_reply.started": "2025-03-15T21:35:33.480707Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df['bert_score_B1_orig'] = bert_score(full_merged_df, 'original', 'simplified_B1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:37:50.893810Z",
     "iopub.status.busy": "2025-03-15T21:37:50.893609Z",
     "iopub.status.idle": "2025-03-15T21:39:54.642729Z",
     "shell.execute_reply": "2025-03-15T21:39:54.641824Z",
     "shell.execute_reply.started": "2025-03-15T21:37:50.893792Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df['bert_score_A2_orig'] = bert_score(full_merged_df, 'original', 'simplified_A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.645340Z",
     "iopub.status.busy": "2025-03-15T21:39:54.645143Z",
     "iopub.status.idle": "2025-03-15T21:39:54.653079Z",
     "shell.execute_reply": "2025-03-15T21:39:54.652179Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.645321Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df[\"bert_score_B1_orig_adjusted\"] = adjust_score_with_length(full_merged_df['bert_score_B1_orig'], full_merged_df[\"num_words_B1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.654168Z",
     "iopub.status.busy": "2025-03-15T21:39:54.653896Z",
     "iopub.status.idle": "2025-03-15T21:39:54.738990Z",
     "shell.execute_reply": "2025-03-15T21:39:54.738119Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.654137Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df[\"bert_score_A2_orig_adjusted\"] = adjust_score_with_length(full_merged_df['bert_score_A2_orig'], full_merged_df[\"num_words_A2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.739937Z",
     "iopub.status.busy": "2025-03-15T21:39:54.739709Z",
     "iopub.status.idle": "2025-03-15T21:39:54.753713Z",
     "shell.execute_reply": "2025-03-15T21:39:54.753001Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.739918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1283.000000\n",
       "mean        0.494115\n",
       "std         0.434568\n",
       "min        -0.746817\n",
       "25%         0.224177\n",
       "50%         0.377510\n",
       "75%         0.627293\n",
       "max         3.054263\n",
       "Name: bert_score_A2_orig_adjusted, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df['bert_score_A2_orig_adjusted'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.754773Z",
     "iopub.status.busy": "2025-03-15T21:39:54.754583Z",
     "iopub.status.idle": "2025-03-15T21:39:54.781288Z",
     "shell.execute_reply": "2025-03-15T21:39:54.780603Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.754754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1283.000000\n",
       "mean        0.560183\n",
       "std         0.493309\n",
       "min        -0.512017\n",
       "25%         0.233982\n",
       "50%         0.418697\n",
       "75%         0.726788\n",
       "max         3.196160\n",
       "Name: bert_score_B1_orig_adjusted, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df['bert_score_B1_orig_adjusted'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.869047Z",
     "iopub.status.busy": "2025-03-15T21:39:54.868853Z",
     "iopub.status.idle": "2025-03-15T21:39:54.880531Z",
     "shell.execute_reply": "2025-03-15T21:39:54.879727Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.869028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1283.000000\n",
       "mean       17.663289\n",
       "std         8.007920\n",
       "min         3.000000\n",
       "25%        12.000000\n",
       "50%        17.000000\n",
       "75%        23.000000\n",
       "max        42.000000\n",
       "Name: num_words_orig, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df['num_words_orig'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.881483Z",
     "iopub.status.busy": "2025-03-15T21:39:54.881313Z",
     "iopub.status.idle": "2025-03-15T21:39:54.890240Z",
     "shell.execute_reply": "2025-03-15T21:39:54.889577Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.881466Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove matches which are the same - need distinct simplifcations\n",
    "full_merged_df = full_merged_df.loc[~(full_merged_df['simplified_B1'] == full_merged_df['simplified_A2']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.891178Z",
     "iopub.status.busy": "2025-03-15T21:39:54.891002Z",
     "iopub.status.idle": "2025-03-15T21:39:54.976289Z",
     "shell.execute_reply": "2025-03-15T21:39:54.975595Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.891159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 16)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:54.977413Z",
     "iopub.status.busy": "2025-03-15T21:39:54.977232Z",
     "iopub.status.idle": "2025-03-15T21:39:55.013456Z",
     "shell.execute_reply": "2025-03-15T21:39:55.012627Z",
     "shell.execute_reply.started": "2025-03-15T21:39:54.977395Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df = full_merged_df.loc[full_merged_df['num_words_orig']> 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:55.014715Z",
     "iopub.status.busy": "2025-03-15T21:39:55.014521Z",
     "iopub.status.idle": "2025-03-15T21:39:55.035436Z",
     "shell.execute_reply": "2025-03-15T21:39:55.034780Z",
     "shell.execute_reply.started": "2025-03-15T21:39:55.014698Z"
    }
   },
   "outputs": [],
   "source": [
    "full_merged_df['high_sim'] = (full_merged_df['bert_score_B1_orig_adjusted'] > full_merged_df['bert_score_B1_orig_adjusted'].quantile(0.5)) & (full_merged_df['bert_score_A2_orig_adjusted'] > full_merged_df['bert_score_A2_orig_adjusted'].quantile(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T21:39:55.036427Z",
     "iopub.status.busy": "2025-03-15T21:39:55.036235Z",
     "iopub.status.idle": "2025-03-15T21:39:55.100801Z",
     "shell.execute_reply": "2025-03-15T21:39:55.099915Z",
     "shell.execute_reply.started": "2025-03-15T21:39:55.036408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 17)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and manually validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-15T21:33:47.226130Z",
     "iopub.status.idle": "2025-03-15T21:33:47.226467Z",
     "shell.execute_reply": "2025-03-15T21:33:47.226370Z",
     "shell.execute_reply.started": "2025-03-15T21:33:47.226360Z"
    }
   },
   "outputs": [],
   "source": [
    "#full_merged_df.to_csv(\"../data/confidential/combined_augmented_dataset_tocheck_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:10.600988Z",
     "iopub.status.busy": "2025-03-30T21:45:10.600718Z",
     "iopub.status.idle": "2025-03-30T21:45:10.698581Z",
     "shell.execute_reply": "2025-03-30T21:45:10.698162Z",
     "shell.execute_reply.started": "2025-03-30T21:45:10.600971Z"
    }
   },
   "outputs": [],
   "source": [
    "manual_alignments = pd.read_csv(f\"{data_path}/combined_augmented_dataset_tocheck_fin.csv\")\n",
    "checked_full_merged_df = pd.concat([full_merged_df, manual_alignments], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:11.405091Z",
     "iopub.status.busy": "2025-03-30T21:45:11.404819Z",
     "iopub.status.idle": "2025-03-30T21:45:11.409876Z",
     "shell.execute_reply": "2025-03-30T21:45:11.409475Z",
     "shell.execute_reply.started": "2025-03-30T21:45:11.405074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 19)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_full_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:35.766103Z",
     "iopub.status.busy": "2025-03-30T21:45:35.765829Z",
     "iopub.status.idle": "2025-03-30T21:45:35.768954Z",
     "shell.execute_reply": "2025-03-30T21:45:35.768547Z",
     "shell.execute_reply.started": "2025-03-30T21:45:35.766086Z"
    }
   },
   "outputs": [],
   "source": [
    "checked_full_merged_df['Match'] = checked_full_merged_df['Match'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:27.097678Z",
     "iopub.status.busy": "2025-03-30T21:45:27.097400Z",
     "iopub.status.idle": "2025-03-30T21:45:27.102032Z",
     "shell.execute_reply": "2025-03-30T21:45:27.101655Z",
     "shell.execute_reply.started": "2025-03-30T21:45:27.097661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Match",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "fa69e7e0-ccb8-46b6-b1b1-fb0f08480cf0",
       "rows": [
        [
         "no",
         "502"
        ],
        [
         "nan",
         "322"
        ],
        [
         "ok",
         "88"
        ],
        [
         "yes",
         "44"
        ],
        [
         "B1",
         "30"
        ],
        [
         "B1_man_sent_match",
         "27"
        ],
        [
         "man_sent_match",
         "20"
        ],
        [
         "man",
         "15"
        ],
        [
         "A2",
         "13"
        ],
        [
         "ref",
         "12"
        ],
        [
         "B1_A2",
         "10"
        ],
        [
         "B1/A2_man_sent_match",
         "7"
        ],
        [
         "A2_man_sent_match",
         "7"
        ],
        [
         "B1_man",
         "6"
        ],
        [
         "A2/B1_man_sent_match",
         "6"
        ],
        [
         "A2_man_sent_match/ref",
         "1"
        ],
        [
         "B1/man_sent_match",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 17
       }
      },
      "text/plain": [
       "Match\n",
       "no                       502\n",
       "nan                      322\n",
       "ok                        88\n",
       "yes                       44\n",
       "B1                        30\n",
       "B1_man_sent_match         27\n",
       "man_sent_match            20\n",
       "man                       15\n",
       "A2                        13\n",
       "ref                       12\n",
       "B1_A2                     10\n",
       "B1/A2_man_sent_match       7\n",
       "A2_man_sent_match          7\n",
       "B1_man                     6\n",
       "A2/B1_man_sent_match       6\n",
       "A2_man_sent_match/ref      1\n",
       "B1/man_sent_match          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_full_merged_df.Match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T21:45:40.021380Z",
     "iopub.status.busy": "2025-03-30T21:45:40.021099Z",
     "iopub.status.idle": "2025-03-30T21:45:40.024730Z",
     "shell.execute_reply": "2025-03-30T21:45:40.024250Z",
     "shell.execute_reply.started": "2025-03-30T21:45:40.021363Z"
    }
   },
   "outputs": [],
   "source": [
    "checked_full_merged_df.loc[checked_full_merged_df.Match.str.startswith(\"B1/\"), 'Match'] = \"B1\"\n",
    "checked_full_merged_df.loc[checked_full_merged_df.Match.str.startswith(\"A2/\"), 'Match'] = \"A2\"\n",
    "checked_full_merged_df_select = checked_full_merged_df.loc[checked_full_merged_df.Match.isin([\"yes\", \"B1\", \"A2\", \"B1_A2\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T07:29:09.976727Z",
     "iopub.status.busy": "2025-03-26T07:29:09.976378Z",
     "iopub.status.idle": "2025-03-26T07:29:09.984674Z",
     "shell.execute_reply": "2025-03-26T07:29:09.983631Z",
     "shell.execute_reply.started": "2025-03-26T07:29:09.976699Z"
    }
   },
   "outputs": [],
   "source": [
    "test_deplain_unmatched = test_deplain.loc[\n",
    "    ((~test_deplain['original'].isin(checked_full_merged_df_select['simplified_B1'])) & (~test_deplain['simplification'].isin(checked_full_merged_df_select['simplified_A2'])))| (test_deplain.index == 455), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T07:29:12.340921Z",
     "iopub.status.busy": "2025-03-26T07:29:12.339940Z",
     "iopub.status.idle": "2025-03-26T07:29:12.495533Z",
     "shell.execute_reply": "2025-03-26T07:29:12.494414Z",
     "shell.execute_reply.started": "2025-03-26T07:29:12.340887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1535825728.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_deplain_unmatched['FK_score'] = test_deplain_unmatched['original'].apply(FK_score)\n"
     ]
    }
   ],
   "source": [
    "test_deplain_unmatched['FK_score'] = test_deplain_unmatched['original'].apply(FK_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T07:29:16.381826Z",
     "iopub.status.busy": "2025-03-26T07:29:16.380779Z",
     "iopub.status.idle": "2025-03-26T07:29:16.391867Z",
     "shell.execute_reply": "2025-03-26T07:29:16.390882Z",
     "shell.execute_reply.started": "2025-03-26T07:29:16.381795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "FK_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1d0ebd73-ae88-4558-a374-1d967ff68d4c",
       "rows": [
        [
         "count",
         "1193.0"
        ],
        [
         "mean",
         "66.13542330259848"
        ],
        [
         "std",
         "21.802465718785545"
        ],
        [
         "min",
         "-35.13"
        ],
        [
         "25%",
         "52.87"
        ],
        [
         "50%",
         "68.77"
        ],
        [
         "75%",
         "80.78"
        ],
        [
         "max",
         "119.19"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    1193.000000\n",
       "mean       66.135423\n",
       "std        21.802466\n",
       "min       -35.130000\n",
       "25%        52.870000\n",
       "50%        68.770000\n",
       "75%        80.780000\n",
       "max       119.190000\n",
       "Name: FK_score, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_deplain_unmatched.FK_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T22:09:53.137774Z",
     "iopub.status.busy": "2025-03-15T22:09:53.137257Z",
     "iopub.status.idle": "2025-03-15T22:09:53.140214Z",
     "shell.execute_reply": "2025-03-15T22:09:53.139581Z",
     "shell.execute_reply.started": "2025-03-15T22:09:53.137752Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_deplain_unmatched.loc[test_deplain_unmatched.FK_score < 50, :].to_csv(\"test_deplain_FK_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:39.664272Z",
     "iopub.status.busy": "2025-03-31T15:50:39.663851Z",
     "iopub.status.idle": "2025-03-31T15:50:39.704286Z",
     "shell.execute_reply": "2025-03-31T15:50:39.703667Z",
     "shell.execute_reply.started": "2025-03-31T15:50:39.664253Z"
    }
   },
   "outputs": [],
   "source": [
    "test_deplain_unmatched_alignments = pd.read_csv(f\"{data_path}/test_deplain_FK_50_checked_fin.csv\", index_col=0)\n",
    "test_deplain_unmatched_checked = pd.concat([test_deplain_unmatched.loc[test_deplain_unmatched.FK_score < 50, :], test_deplain_unmatched_alignments.loc[:, \"Match\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:40.209681Z",
     "iopub.status.busy": "2025-03-31T15:50:40.209275Z",
     "iopub.status.idle": "2025-03-31T15:50:40.227823Z",
     "shell.execute_reply": "2025-03-31T15:50:40.227359Z",
     "shell.execute_reply.started": "2025-03-31T15:50:40.209662Z"
    }
   },
   "outputs": [],
   "source": [
    "test_deplain_unmatched_checked['Match'] = test_deplain_unmatched_checked['Match'].astype(str)\n",
    "test_deplain_unmatched_select = test_deplain_unmatched_checked.loc[test_deplain_unmatched_checked['Match'] == \"yes\", ['original', 'simplification']]\n",
    "test_deplain_unmatched_select.columns = [\"original\", \"simplified_A2\"]\n",
    "test_deplain_unmatched_select['Match'] = \"B1_A2\"\n",
    "test_deplain_unmatched_select['orig'] = \"B1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:40.750378Z",
     "iopub.status.busy": "2025-03-31T15:50:40.749963Z",
     "iopub.status.idle": "2025-03-31T15:50:40.755289Z",
     "shell.execute_reply": "2025-03-31T15:50:40.754838Z",
     "shell.execute_reply.started": "2025-03-31T15:50:40.750360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\3887817780.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  checked_full_merged_df_select_t['orig'] = \"orig\"\n"
     ]
    }
   ],
   "source": [
    "checked_full_merged_df_select_t = checked_full_merged_df_select[['original', 'simplified_B1', 'simplified_A2', 'Match']]\n",
    "checked_full_merged_df_select_t.loc[checked_full_merged_df_select_t['Match']== \"B1_A2\", 'original'] = checked_full_merged_df_select_t.loc[checked_full_merged_df_select_t['Match']== \"B1_A2\", 'simplified_B1']\n",
    "checked_full_merged_df_select_t.loc[checked_full_merged_df_select_t['Match'].isin([\"B1_A2\", 'A2']), 'simplified_B1'] = None\n",
    "checked_full_merged_df_select_t.loc[checked_full_merged_df_select_t['Match'] == \"B1\", 'simplified_A2'] = None\n",
    "checked_full_merged_df_select_t['orig'] = \"orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:45.028522Z",
     "iopub.status.busy": "2025-03-31T15:50:45.027934Z",
     "iopub.status.idle": "2025-03-31T15:50:45.033208Z",
     "shell.execute_reply": "2025-03-31T15:50:45.032781Z",
     "shell.execute_reply.started": "2025-03-31T15:50:45.028500Z"
    }
   },
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([test_deplain_unmatched_select, checked_full_merged_df_select_t]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:45.833628Z",
     "iopub.status.busy": "2025-03-31T15:50:45.833282Z",
     "iopub.status.idle": "2025-03-31T15:50:45.840599Z",
     "shell.execute_reply": "2025-03-31T15:50:45.840191Z",
     "shell.execute_reply.started": "2025-03-31T15:50:45.833611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Match",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6d42a82c-c957-4f5d-8278-61cf50334a74",
       "rows": [
        [
         "B1_A2",
         "68"
        ],
        [
         "yes",
         "44"
        ],
        [
         "B1",
         "38"
        ],
        [
         "A2",
         "19"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Match\n",
       "B1_A2    68\n",
       "yes      44\n",
       "B1       38\n",
       "A2       19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.Match.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:48.557089Z",
     "iopub.status.busy": "2025-03-31T15:50:48.556647Z",
     "iopub.status.idle": "2025-03-31T15:50:48.561301Z",
     "shell.execute_reply": "2025-03-31T15:50:48.560901Z",
     "shell.execute_reply.started": "2025-03-31T15:50:48.557070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "orig",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "fa431a33-9ae5-4db1-b63e-056879705403",
       "rows": [
        [
         "orig",
         "111"
        ],
        [
         "B1",
         "58"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "orig\n",
       "orig    111\n",
       "B1       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.orig.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:50:50.247836Z",
     "iopub.status.busy": "2025-03-31T15:50:50.247433Z",
     "iopub.status.idle": "2025-03-31T15:50:50.250850Z",
     "shell.execute_reply": "2025-03-31T15:50:50.250470Z",
     "shell.execute_reply.started": "2025-03-31T15:50:50.247817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169, 5)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:51:31.816284Z",
     "iopub.status.busy": "2025-03-31T15:51:31.816132Z",
     "iopub.status.idle": "2025-03-31T15:51:33.408322Z",
     "shell.execute_reply": "2025-03-31T15:51:33.407737Z",
     "shell.execute_reply.started": "2025-03-31T15:51:31.816267Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"WordReductionRatio\"] = word_ratios\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"WordCountOrig\"] = word_counts\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SentenceReductionRatio\"] = sentence_ratios\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"WordReductionRatio\"] = word_ratios\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"WordCountOrig\"] = word_counts\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1522100671.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"SentenceReductionRatio\"] = sentence_ratios\n"
     ]
    }
   ],
   "source": [
    "metrics_A2 = compute_text_metrics(final_dataset[pd.notna(final_dataset['simplified_A2'])], 'original', 'simplified_A2')\n",
    "metrics_B1 = compute_text_metrics(final_dataset[pd.isna(final_dataset['simplified_A2'])], 'original', 'simplified_B1')\n",
    "final_dataset_w_metrics = pd.concat([metrics_A2, metrics_B1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:51:33.430710Z",
     "iopub.status.busy": "2025-03-31T15:51:33.430558Z",
     "iopub.status.idle": "2025-03-31T15:51:33.442902Z",
     "shell.execute_reply": "2025-03-31T15:51:33.442541Z",
     "shell.execute_reply.started": "2025-03-31T15:51:33.430694Z"
    }
   },
   "outputs": [],
   "source": [
    "final_dataset_w_metrics['category'] = np.where(\n",
    "    final_dataset_w_metrics['SentenceReductionRatio'] < 1, \n",
    "    \"split\", \n",
    "    np.where(final_dataset_w_metrics['WordReductionRatio'] >= 1.5, \"delete\", \"paraphrase\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:52:28.409987Z",
     "iopub.status.busy": "2025-03-31T15:52:28.409635Z",
     "iopub.status.idle": "2025-03-31T15:52:28.414357Z",
     "shell.execute_reply": "2025-03-31T15:52:28.414005Z",
     "shell.execute_reply.started": "2025-03-31T15:52:28.409970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "original",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0981c884-02d7-43e7-93eb-1821e4369c10",
       "rows": [
        [
         "14 Prozent der Befragten sagten, dass sie schon Erfahrungen mit CBD-Produkten gemacht haben.",
         "2"
        ],
        [
         "Arbeitnehmer nennt man Personen, die in Firmen arbeiten.",
         "1"
        ],
        [
         "Mindestens sechs Tote durch Hurrikan Laura in den USA.",
         "1"
        ],
        [
         "In Kirchschlag in der Buckligen Welt ( Bezirk Wiener Neustadt ) soll ein 14-Jähriger am Montag seine Mutter erstochen haben.",
         "1"
        ],
        [
         "Die offizielle Gesamtzahl der Krankheitsfälle in Festland-China durch das inzwischen offiziell als Covid-19 bezeichnete Virus wuchs damit auf mehr als 44.200 an.",
         "1"
        ],
        [
         "Die Weltgesundheitsorganisation ( WHO ) hat erneut einen Rekord an neu gemeldeten Corona-Fällen innerhalb eines Tages registriert.",
         "1"
        ],
        [
         "Es ist ganz normal, dass in der Antarktis manchmal Eisberge abbrechen, sagen die Forscher.",
         "1"
        ],
        [
         "Bei den Weißhandgibbons im Tiergarten Schönbrunn hat es Nachwuchs gegeben.",
         "1"
        ],
        [
         "Erst im Alter von drei Monaten wird das Jungtier erste Kletterversuche unternehmen.",
         "1"
        ],
        [
         "Im niederösterreichischen Post-Verteilungszentren Hagenbrunn wurden 63 Mitarbeiter positiv getestet, die in Wien wohnen, erläuterte Huber.",
         "1"
        ],
        [
         "Grippewelle in Österreich derzeit wohl auf dem Höhepunkt.",
         "1"
        ],
        [
         "Emma und Maximilian haben 2019 die Hitliste der Vornamen Neugeborener angeführt, wobei der Mädchenname zum ersten Mal den ersten Rang einnahm, während Maximilian sich seine frühere Spitzenposition zurückeroberte.",
         "1"
        ],
        [
         "Boris Johnson wird neuer britischer Premierminister.",
         "1"
        ],
        [
         "Im zweiten Halbjahr 2019 war der Anteil jener, die krank in die Arbeit gingen, noch bei knapp unter 40 Prozent gelegen.",
         "1"
        ],
        [
         "Wien überzeugte vor allem bei Sicherheit, Gesundheit und sauberer Umwelt.",
         "1"
        ],
        [
         "Der Friedensvertrag sieht unter anderem vor, dass einige der Renamo-Milizen in die Armee und die Polizei des Landes integriert werden.",
         "1"
        ],
        [
         "Wissenschafter glauben nicht, dass der Klimawandel schuld an dem Eisberg ist.",
         "1"
        ],
        [
         "Ab Juni werden vielleicht weitere Corona-Regeln gelockert.",
         "1"
        ],
        [
         "In Namibia ist am Mittwoch ein 59-jähriger Oberösterreicher von einem Elefanten tot getrampelt worden.",
         "1"
        ],
        [
         "Das hat Bildungsminister Heinz Faßmann ( ÖVP ) bei einer Pressekonferenz am Freitag bekanntgegeben.",
         "1"
        ],
        [
         "Zum Jahrestag des US-Ausstiegs aus dem internationalen Atomabkommen mit dem Iran hat der iranische Präsident Hassan Rouhani einen Teilausstieg seines Landes aus der Vereinbarung bekanntgegeben.",
         "1"
        ],
        [
         "Aber wir können uns sicher sein : Nächstes Jahr kehrt das Wachstum zurück und unser Comeback wird beginnen, so Kurz.",
         "1"
        ],
        [
         "Kümmern will sich Brandstätter im Nationalrat vor allem um Wissenschaft und Forschung.",
         "1"
        ],
        [
         "Am Mittwoch soll ein Mann in Oberösterreich mit einem Bogen einen Pfeil auf seine Ex-Freundin geschossen haben.",
         "1"
        ],
        [
         "In Wien wurden knapp 14.000 Neuerkrankungen gemeldet, in Graz sind es mehr als 6.500.",
         "1"
        ],
        [
         "Die Regierung hat am Dienstag die Details ihrer Steuerreform vorgestellt.",
         "1"
        ],
        [
         "Da hat die Polizei in Enns ( Bezirk Linz-Land ) am Dienstag nicht schlecht gestaunt : Ein Pony reiste im - mit Stroh ausgelegten - Fond eines Kleinwagens.",
         "1"
        ],
        [
         "Die Türkei und die USA hatten am Donnerstag eine fünftägige Waffenruhe für Nordsyrien vereinbart.",
         "1"
        ],
        [
         "Das geht meines Erachtens zu weit, sagte der Bundespräsident.",
         "1"
        ],
        [
         "AUA spart noch mehr und baut über 650 Jobs bis 2023 ab.",
         "1"
        ],
        [
         "Auf dem Schiff mit Tauchtouristen befanden sich 39 Menschen, fünf Crew-Mitglieder konnten sich retten.",
         "1"
        ],
        [
         "Ein 71-Jähriger hat am Montag seine Ehefrau in Sautens in Tirol ( Bezirk Imst ) auf offener Straße niedergeschlagen und mit einem Messer attackiert.",
         "1"
        ],
        [
         "Vor 14 Tagen sind durch eine Lawine 3 Menschen in den Bergen der Rocky Mountains in Kanada gestorben.",
         "1"
        ],
        [
         "Die Passagiere des Ausflugsschiffes schliefen im Bootsinneren, als das Feuer aus noch unbekannten Gründen ausbrach.",
         "1"
        ],
        [
         "Laut Zeitungsberichten wollte die Familie einen Hubschrauber-Ausflug über Mallorca machen.",
         "1"
        ],
        [
         "In Großbritannien und den Niederlanden haben am Donnerstag die Europawahlen begonnen.",
         "1"
        ],
        [
         "Die Ermittlungen ergaben inzwischen Hinweise, dass der Verdächtige während der Schüsse keine Hilfe von anderen Personen bekommen hat, hieß es vonseiten der Staatsanwaltschaft.",
         "1"
        ],
        [
         "Die USA hat Waren aus China erneut mit Straf-Zöllen belegt.",
         "1"
        ],
        [
         "200 Massengräber in früheren IS-Gebieten im Irak entdeckt.",
         "1"
        ],
        [
         "Ebenso wollen einige ( 25 Prozent ) erst auf das neue Mobilfunknetz wechseln, wenn es Standardangebot ist oder es keine Alternative mehr gibt.",
         "1"
        ],
        [
         "Als schlechteste Hauptdarsteller wurden John Travolta ( The Fanatic und Trading Paint ) und Hilary Duff ( The Haunting of Sharon Tate ) ausgewählt.",
         "1"
        ],
        [
         "Nach dem Ausbruch der Lungenkrankheit Covid-19 in Südkorea mehren sich die Anzeichen für einen langsameren Anstieg bei den Infizierungsfällen.",
         "1"
        ],
        [
         "Glee -Star Naya Rivera ist tot - Leiche im See gefunden.",
         "1"
        ],
        [
         "Der Tiergarten Schönbrunn ist eine der beliebtesten Attraktionen Wiens, der älteste Zoo weltweit und gehört zum UNESCO Weltkulturerbe.",
         "1"
        ],
        [
         "Vom einstigen Profi-Wrestler zum absoluten Topverdiener in Hollywood : Der Fast and Furious -Star Dwayne Johnson ( 47 ) ist laut dem US-Magazin Forbes zum bestbezahlten Schauspieler der Filmindustrie aufgestiegen.",
         "1"
        ],
        [
         "Im Vergleich zum Jahr 2001 haben sich die Zahlen für Burschen in Österreich verbessert, bei den Mädchen hingegen leicht verschlechtert.",
         "1"
        ],
        [
         "Auf dem Bild sieht man die neue Giraffe im Tiergarten Schönbrunn.",
         "1"
        ],
        [
         "Eine couragierte Autofahrerin hat am Donnerstag in Lohnsburg im Bezirk Ried im Innkreis einen Alkolenker gestoppt und am Weiterfahren gehindert.",
         "1"
        ],
        [
         "Ein Pferd ist am Dienstag auf der Westautobahn ( A1 ) bei Allhaming in Oberösterreich als Geisterfahrer auf der Wiener Richtungsfahrbahn unterwegs gewesen.",
         "1"
        ],
        [
         "Die Bundesregierung hat nach ihrem ersten Herbst-Ministerrat am Mittwoch trotz steigender Infektionszahlen keine weiteren Verschärfungen der Coronamaßnahmen bekanntgegeben.",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 168
       }
      },
      "text/plain": [
       "original\n",
       "14 Prozent der Befragten sagten, dass sie schon Erfahrungen mit CBD-Produkten gemacht haben.                                                                         2\n",
       "Arbeitnehmer nennt man Personen, die in Firmen arbeiten.                                                                                                             1\n",
       "Mindestens sechs Tote durch Hurrikan Laura in den USA.                                                                                                               1\n",
       "In Kirchschlag in der Buckligen Welt ( Bezirk Wiener Neustadt ) soll ein 14-Jähriger am Montag seine Mutter erstochen haben.                                         1\n",
       "Die offizielle Gesamtzahl der Krankheitsfälle in Festland-China durch das inzwischen offiziell als Covid-19 bezeichnete Virus wuchs damit auf mehr als 44.200 an.    1\n",
       "                                                                                                                                                                    ..\n",
       "Das neuartige Virus hatte sich Ende 2019 auf einem Markt in Wuhan ausgebreitet, auf dem Wildtiere wie Fledermäuse und Schuppentiere verkauft wurden.                 1\n",
       "Dabei werde es am kommenden Mittwoch um die Rekord-Gewinnsumme von 14 Millionen Euro gehen, teilten die Lotterien am Sonntagabend mit.                               1\n",
       "Ist dies der Fall, wird auf grün geschaltet.                                                                                                                         1\n",
       "Wie bekannt wurde, muss die Getriebe- und Motoren-Fabrik von Opel in Wien-Aspern 350 bis 400 Stellen abbauen.                                                        1\n",
       "Das neue Schuljahr bringt das Aus für fast 30 Schulstandorte, das sind viermal so viele wie im Vorjahr.                                                              1\n",
       "Name: count, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset_w_metrics['original'].value_counts() #one row go put twice in test, so deduplication is OK after splitting to preserve the train_df selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:51:33.443780Z",
     "iopub.status.busy": "2025-03-31T15:51:33.443384Z",
     "iopub.status.idle": "2025-03-31T15:51:33.494101Z",
     "shell.execute_reply": "2025-03-31T15:51:33.493752Z",
     "shell.execute_reply.started": "2025-03-31T15:51:33.443762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9ff1bbbb-7b5c-4d96-a0ea-a5aaa659cbc8",
       "rows": [
        [
         "paraphrase",
         "92"
        ],
        [
         "split",
         "45"
        ],
        [
         "delete",
         "32"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "category\n",
       "paraphrase    92\n",
       "split         45\n",
       "delete        32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset_w_metrics.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:53:42.793090Z",
     "iopub.status.busy": "2025-03-31T15:53:42.792598Z",
     "iopub.status.idle": "2025-03-31T15:53:42.809803Z",
     "shell.execute_reply": "2025-03-31T15:53:42.809438Z",
     "shell.execute_reply.started": "2025-03-31T15:53:42.793072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      "category    Match\n",
      "delete      A2        5\n",
      "            B1        5\n",
      "            B1_A2     3\n",
      "            yes       5\n",
      "paraphrase  A2        4\n",
      "            B1       12\n",
      "            B1_A2    24\n",
      "            yes      15\n",
      "split       A2        2\n",
      "            B1        5\n",
      "            B1_A2    14\n",
      "            yes       6\n",
      "dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "category    Match\n",
      "delete      A2        3\n",
      "            B1        3\n",
      "            B1_A2     2\n",
      "            yes       4\n",
      "paraphrase  A2        2\n",
      "            B1        9\n",
      "            B1_A2    14\n",
      "            yes       7\n",
      "split       A2        1\n",
      "            B1        3\n",
      "            B1_A2     9\n",
      "            yes       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stratify using both 'Category' and 'Match'\n",
    "train, temp_df = train_test_split(final_dataset_w_metrics, test_size=69, stratify=final_dataset_w_metrics[['category', 'Match']], random_state=42)\n",
    "\n",
    "# Second split: Get test (60) and remaining validation (9)\n",
    "test, few_shot = train_test_split(temp_df, test_size=9, stratify=temp_df['category'], random_state=42)\n",
    "\n",
    "# Print the distribution to check balance\n",
    "print(\"Train distribution:\")\n",
    "print(train.groupby(['category', 'Match']).size())\n",
    "\n",
    "print(\"\\nTest distribution:\")\n",
    "print(test.groupby(['category', 'Match']).size())\n",
    "# Now, `train` has 100 rows and `test` has 60 rows, stratified by 'Category' and 'Match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:54:00.329824Z",
     "iopub.status.busy": "2025-03-31T15:54:00.329499Z",
     "iopub.status.idle": "2025-03-31T15:54:00.334009Z",
     "shell.execute_reply": "2025-03-31T15:54:00.333558Z",
     "shell.execute_reply.started": "2025-03-31T15:54:00.329806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test distribution:\n",
      "category    Match\n",
      "delete      A2       1\n",
      "            B1       1\n",
      "paraphrase  B1_A2    2\n",
      "            yes      3\n",
      "split       A2       1\n",
      "            yes      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest distribution:\")\n",
    "print(few_shot.groupby(['category', 'Match']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:54:16.032366Z",
     "iopub.status.busy": "2025-03-31T15:54:16.032038Z",
     "iopub.status.idle": "2025-03-31T15:54:16.038322Z",
     "shell.execute_reply": "2025-03-31T15:54:16.037938Z",
     "shell.execute_reply.started": "2025-03-31T15:54:16.032347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\1804514663.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  few_shot.groupby('category').apply(lambda x: x.sample(2, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "training_pairs = (\n",
    "    few_shot.groupby('category').apply(lambda x: x.sample(2, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    "    [['original', 'simplified_A2', 'category', 'Match']]\n",
    "    .values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:57:22.394473Z",
     "iopub.status.busy": "2025-03-31T15:57:22.394076Z",
     "iopub.status.idle": "2025-03-31T15:57:22.397489Z",
     "shell.execute_reply": "2025-03-31T15:57:22.397086Z",
     "shell.execute_reply.started": "2025-03-31T15:57:22.394455Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.drop_duplicates(subset = \"original\") #correction here - move one random few-shot to test as one duplicate\n",
    "unmatched_few_shot = few_shot.loc[~(few_shot['original'].isin([orig for orig, simp, cat, mat in training_pairs])), :].reset_index(drop = True)\n",
    "test = pd.concat([test, pd.DataFrame(unmatched_few_shot.loc[[0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T15:58:29.763391Z",
     "iopub.status.busy": "2025-03-31T15:58:29.762831Z",
     "iopub.status.idle": "2025-03-31T15:58:29.767150Z",
     "shell.execute_reply": "2025-03-31T15:58:29.766619Z",
     "shell.execute_reply.started": "2025-03-31T15:58:29.763368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 9)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to both dataframes\n",
    "train_transformed = transform_to_simplifications(train)\n",
    "test_transformed = transform_to_simplifications(test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ATS (train+test), LLM (train+test) and Human Scores (test only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Automatic Simplifications\n",
    "train_ATS = pd.read_csv(f'{data_path}/train_ATS_final_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ATS = train_ATS.set_index(\"Unnamed: 0\")\n",
    "train_w_ATS = train_transformed.merge(train_ATS, left_index=True, right_index=True).drop(columns = [\"Unnamed: 0.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_ATS = train_w_ATS.melt(\n",
    "    id_vars=['original', 'simplifications'],              # columns to keep fixed\n",
    "    value_vars=[col for col in train_ATS.columns if col.startswith('ATS_')],  # ATS model outputs\n",
    "    var_name='ATS_Model',              # new column name for model name\n",
    "    value_name='simplification'        # new column name for the simplified text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_ATS['simplification'] = train_w_ATS['simplification'].apply(clean_output)\n",
    "train_w_ATS = train_w_ATS.sample(frac = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_LLM = pd.read_csv(f\"{data_path}/LLM_scores_train.csv\")\n",
    "train_w_LLM = pd.concat([train_w_ATS, train_LLM.drop(columns = [\"Unnamed: 0\", \"simplification\"])], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ATS = pd.read_csv(f'{data_path}/test_ATS_final_melted_final_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed['orig_ID'] = test_transformed.reset_index(drop = True).index+1\n",
    "test_w_ATS = pd.merge(\n",
    "    test_transformed,\n",
    "    test_ATS),\n",
    "    on=\"orig_ID\"\n",
    ").sort_values(by = \"Unnamed: 0\").drop(columns = ['Unnamed: 0', 'orig_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_29708\\2707292544.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_df_final_melted_60 = test_w_ATS.groupby(\"ATS_Model\").apply(lambda x: x.sample(n=10, random_state=42)).reset_index(drop=True).sample(frac = 1, random_state = 42)\n"
     ]
    }
   ],
   "source": [
    "test_df_final_melted_60 = test_w_ATS.groupby(\"ATS_Model\").apply(lambda x: x.sample(n=10, random_state=42)).reset_index(drop=True).sample(frac = 1, random_state = 42)\n",
    "test_ids = test_df_final_melted_60['simp_ID'].unique()\n",
    "# Create the remaining dataset excluding those 60 rows\n",
    "remaining_df = test_w_ATS[~test_w_ATS['simp_ID'].isin(test_ids)].sample(frac=1, random_state=42)\n",
    "\n",
    "# Concatenate test set (first 60) + shuffled remaining\n",
    "# This was done because originally we thought we could only get 60 rows of human-eval data; so now everything is reshuffled to keep consistent.\n",
    "test_w_ATS_reshuffled = pd.concat([test_df_final_melted_60, remaining_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_scores_test = pd.read_csv(f'{data_path}/LLM_scores_test.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w_LLM = pd.concat([test_w_ATS_reshuffled.drop(columns = ['simp_ID', 'WordReductionRatio', 'WordCountOrig', 'SentenceReductionRatio', 'ROUGE1_Score']), LLM_scores_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_csv(f\"{data_path}/human_grading.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w_human = pd.concat([test_w_LLM, human_df],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_LLM.to_csv(f'{data_path}/SimpEvalDE_train.csv')\n",
    "test_w_human.to_csv(f'{data_path}/SimpEvalDE_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce total score grading used in the DETECT metric, use this formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_score(row, columns):\n",
    "        simp, meaning, fluency = row[columns[0]], row[columns[1]], row[columns[2]]\n",
    "        return round(min(simp, meaning, fluency)) if min(simp, meaning, fluency) < 25 else round(0.4 * meaning + 0.4 * simp + 0.2 * fluency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATS_LENS_DE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
